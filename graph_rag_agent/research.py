# research.py - ç§»é™¤JSONæ ¼å¼é™åˆ¶çš„ç‰ˆæœ¬

from neo4j import GraphDatabase
from neo4j_graphrag.embeddings import OpenAIEmbeddings
from vertexai.generative_models import GenerationConfig
from neo4j_graphrag.llm.vertexai_llm import VertexAILLM
from neo4j_graphrag.indexes import create_vector_index
from neo4j_graphrag.retrievers import VectorRetriever
from neo4j_graphrag.retrievers import VectorCypherRetriever
from neo4j_graphrag.generation import RagTemplate
from neo4j_graphrag.generation.graphrag import GraphRAG
from neo4j_graphrag.llm import OpenAILLM
import os
from dotenv import load_dotenv

load_dotenv()
NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
NEO4J_DATABASE= os.getenv("NEO4J_DATABASE")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY=os.getenv("GOOGLE_API_KEY")

driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD),database=NEO4J_DATABASE)
embedder = OpenAIEmbeddings(model="text-embedding-ada-002", api_key=OPENAI_API_KEY)

# ğŸ”§ ä¿®æ­£ï¼šç§»é™¤ JSON æ ¼å¼é™åˆ¶ï¼Œä½¿ç”¨è‡ªç„¶æ–‡å­—å›æ‡‰
llm = OpenAILLM(
    model_name='gpt-4.1-mini',
    model_params={'temperature': 0}  # ç§»é™¤ JSON æ ¼å¼è¦æ±‚
)

create_vector_index(driver, name="text_embeddings", label="Chunk",
                   embedding_property="embedding", dimensions=1536, similarity_fn="cosine")

vc_retriever = VectorCypherRetriever(
   driver,
   index_name="text_embeddings",
   embedder=embedder,
   
   retrieval_query="""
//1) Go out 2-3 hops in the entity graph and get relationships
WITH node AS chunk
MATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,2}()
UNWIND relList AS rel

//2) collect relationships and text chunks
WITH collect(DISTINCT chunk) AS chunks,
 collect(DISTINCT rel) AS rels

//3) format and return context
RETURN '=== text ===n' + apoc.text.join([c in chunks | c.text], 'n---n') + 'nn=== kg_rels ===n' +
 apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], 'n---n') AS info
"""
)

# ğŸ”§ ä¿®æ­£ï¼šç°¡åŒ–ä¸¦æ”¹å–„ RAG æ¨¡æ¿
rag_template = RagTemplate(
    template='''
è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œï¼Œä¸¦ç‚ºé•·è¼©æä¾›æ¸…æ™°æ˜“æ‡‚çš„å¥åº·è³‡è¨Šï¼š

å•é¡Œï¼š{query_text}

åƒè€ƒè³‡æ–™ï¼š
{context}

è«‹éµå¾ªä»¥ä¸‹å›ç­”åŸå‰‡ï¼š
- ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
- æä¾›è©³ç´°ä¸”å¯¦ç”¨çš„è³‡è¨Š
- åªæ ¹æ“šæä¾›çš„åƒè€ƒè³‡æ–™å›ç­”
- ä»¥æ¸…æ™°çš„æ®µè½å’Œé©ç•¶çš„æ¨™é¡Œçµ„ç¹”å…§å®¹
- å¦‚æœè³‡æ–™ä¸è¶³ä»¥å›ç­”å•é¡Œï¼Œè«‹èª å¯¦èªªæ˜

å›ç­”ï¼š
''', 
    system_instructions="æ‚¨æ˜¯å°ˆæ¥­çš„é†«ç™‚å¥åº·é¡§å•ï¼Œå°ˆé–€ç‚ºé•·è¼©æä¾›æ˜“æ‡‚çš„å¥åº·è³‡è¨Šå’Œå»ºè­°ã€‚",
    expected_inputs=['query_text', 'context']
)

rag = GraphRAG(llm=llm, retriever=vc_retriever, prompt_template=rag_template)

def graph_rag(input: str):
    """åŸ·è¡Œåœ–å½¢RAGæŸ¥è©¢ä¸¦è¿”å›æ¸…ç†å¾Œçš„çµæœ"""
    try:
        # åŸ·è¡ŒRAGæŸ¥è©¢
        result = rag.search(input, retriever_config={'top_k': 5})
        
        # ç²å–ç­”æ¡ˆ
        answer = result.answer
        
        # ğŸ”§ æ¸…ç†å¯èƒ½çš„JSONæ ¼å¼å›æ‡‰
        if isinstance(answer, str) and answer.strip().startswith('{'):
            try:
                import json
                parsed = json.loads(answer)
                if isinstance(parsed, dict):
                    # å°‡JSONè½‰æ›ç‚ºè‡ªç„¶æ–‡å­—æ ¼å¼
                    answer = convert_json_to_text(parsed)
            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±æ•—ï¼Œä¿æŒåŸå§‹æ–‡å­—
                pass
        
        return answer
        
    except Exception as e:
        error_msg = f"çŸ¥è­˜åœ–è­œæŸ¥è©¢é‡åˆ°å•é¡Œï¼š{str(e)}"
        print(f"âŒ graph_rag éŒ¯èª¤: {error_msg}")
        return error_msg

def convert_json_to_text(data):
    """å°‡JSONçµæ§‹è½‰æ›ç‚ºè‡ªç„¶æ–‡å­—æ ¼å¼"""
    if isinstance(data, dict):
        result_parts = []
        
        # è™•ç†ä¸»è¦æ¨™é¡Œ
        for main_key, main_value in data.items():
            result_parts.append(f"## {main_key}")
            
            if isinstance(main_value, dict):
                for key, value in main_value.items():
                    if isinstance(value, dict):
                        result_parts.append(f"\n**{key}ï¼š**")
                        for sub_key, sub_value in value.items():
                            if isinstance(sub_value, list):
                                result_parts.append(f"- **{sub_key}ï¼š** {', '.join(map(str, sub_value))}")
                            else:
                                result_parts.append(f"- **{sub_key}ï¼š** {sub_value}")
                    elif isinstance(value, list):
                        result_parts.append(f"\n**{key}ï¼š**")
                        for item in value:
                            result_parts.append(f"- {item}")
                    else:
                        result_parts.append(f"\n**{key}ï¼š** {value}")
            elif isinstance(main_value, list):
                for item in main_value:
                    result_parts.append(f"- {item}")
            else:
                result_parts.append(str(main_value))
        
        return '\n'.join(result_parts)
    
    elif isinstance(data, list):
        return '\n'.join([f"- {item}" for item in data])
    
    else:
        return str(data)

